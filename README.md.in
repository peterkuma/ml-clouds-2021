# Code for the paper "Machine learning of cloud types shows higher climate sensitivity is associated with lower cloud biases"

Peter Kuma<sup>1</sup>, Frida Bender<sup>1</sup>, Alex Schuddeboom<sup>2</sup>, Adrian McDonald<sup>2</sup>, Ã˜yvind Seland<sup>3</sup>

<sup>1</sup>Department of Meteorology (MISU), Stockholm University, Stockholm, Sweden\
<sup>2</sup>School of Physical and Chemical Sciences, Christchurch, Aotearoa New Zealand\
<sup>3</sup>Norwegian Meteorological Institute, Oslo, Norway

This repository contains code for the paper "Machine learning of cloud types
shows higher climate sensitivity is associated with lower cloud biases".

If you have any questions about the code you can contact the authors or submit
an Issue on GitHub.

## Requirements

The code can be run on a Linux distribution with the following software
(exact versions are listed for reproducibility, but newer version may work
equally well):

- Python 3.7.3
- Cython 0.29.2
- aria2 1.34.0

and Python packages:

- tensorflow 1.14.0
- scipy 1.7.0
- numpy 1.21.1
- matplotlib 3.5.1
- pymc3 3.11.2
- pst-format 1.1.1
- aquarius-time 0.1.1
- ds-format 1.2.0
- pyproj 2.6.1
- pandas 1.3.0

On Debian-based Linux distributions (Ubuntu, Debian, Devuan, ...), the required
software can be installed with:

```sh
apt install python3 cython3 aria2
```

We recommend installing the Python packages in a virtual environment (venv):

```sh
python3 -m venv venv
. venv/bin/activate
```

To install the Python packages:

```sh
pip3 install -r requirements.txt
```

## Overview

Below is an overview of the available commands showing their dependencies
and the paper figures they produce.

```
prepare_samples
  tf
    plot_idd_stations [Figure 1a]
    plot_sample [Figure 1b, c]
    plot_training_history [Figure 3]
    merge_samples
      calc_dtau_pct
        plot_dtau_pct [Figure 6]
      calc_geo_cto
        plot_geo_cto [Figure 4, 5]
        plot_geo_cto_rmse [Figure 11b, c, d]
      calc_cto
        plot_cto [Figure 10]
        calc_cto_ecs
          plot_cto_ecs [Figure 11a]
plot_tf_scheme [Figure 2]
```

## Input datasets

### Historical Unidata Internet Data Distribution (IDD) Global Observational Data

The IDD dataset contains ship and buoy records from the Global Telecommunication
System. It can be downloaded from [Research Data
Archive](https://rda.ucar.edu/datasets/ds336.0/). The relevant files are
the SYNOP and BUOY NetCDF files (2008-present), and the HISTSURFACEOBS tar
files (2003-2008). The HISTSURFACEOBS files have to be unpacked after
downloading.

In the examples below it is assumed that the IDD files are stored under
`data/idd/synop` and `data/idd/buoy` for the synop and buoy files,
respectively.

### Climate Model Intercomparison Project (CMIP)

CMIP5 and CMIP6 model output can be downloaded from the
[CMIP5](https://esgf-node.llnl.gov/projects/cmip5/) and
[CMIP6](https://esgf-node.llnl.gov/projects/cmip6/) data archives.  The
relevant experiments are `historical` (`hist-1950` in the case of EC-Earth3P)
and `abrupt-4xCO2`. The required variables are `tas` in the monthly (`mon`)
frequency, and `rlut`, `rlutcs`, `rsdt`, `rsut`, `rsutcs` in the daily (`day`)
frequency.

The command `download_cmip` can be used to create a list of CMIP files
to download from a JSON catalog file, which can be created on the archive site
above (`return results as JSON` on the search page). `limit=` in the URL to the
JSON file should be changed to 10000, and `Show All Replicas` should be
selected when searching. The resulting file list can be used with the program
aria2c as `aria2c -i <file>` to download to files. Afterwards, use
the commands `create_by_model` and `create_by_var` to create an index of
symlinks in the directory where the downloaded files are stored. This index is
required by the main commands.

In the examples below it is assumed that the CMIP5 and CMIP6 files are stored
in `data/cmip5/<experiment>/<frequency/` and
`data/cmip6/<experiment>/<frequency/`, respectively, where `<experiment>`
is either `historical` (for both `historical` and `hist-1950`) or
`abrupt-4xCO2` and `<frequency>` is `day` or `mon`.

### GISS Surface Temperature Analysis (GISTEMP)

The GISTEMP dataset is in `data/gistemp` available as the original file
(CSV) and converted to NetCDF with `gistemp_to_nc` (required by the main
commands). The original dataset has been downloaded from [NASA
GISS](https://data.giss.nasa.gov/gistemp/), and the original terms of use of
this dataset apply.

## Data directory

The data directory should contain the necessary input files, and it is also
where output from the commands is written. Below is a description of its
structure:

```
data
  ann
    ceres.h5: NetCDF file of ANN model generated by tf train from CERES data.
  cmip5
    abrupt-4xCO2
      day: Daily CMIP5 files in the abrupt-4xCO2 experiment.
        by-model: Directory created by create_by_model.
  cmip6
    historical
      day: Daily CMIP6 files in the historical experiment.
        by-model: Directory created by create_by_model.
    hist-1950
      day: Daily CMIP6 EC-Earth3P files in the hist-1950 experiment.
        by-model: Directory created by create_by_model.
    abrupt-4xCO2
      day: Daily CMIP6 files in the abrupt-4xCO2 experiment.
        by-model: Directory created by create_by_model.
  ecs
    ecs.csv: ECS, TCR and CLD values for CMIP5 and CMIP6 models.
  idd
    buoy: IDD buoy files.
    syop: IDD synop files.
  samples
    historical
	abrupt-4xCO2
  samples_stats
    historical
	abrupt-4xCO2
  cto
    historical
	  2003-2014
	abrupt-4xCO2
	  1850-1949
  geo_cto
    historical
	  2003-2014
	abrupt-4xCO2
	  1850-1949
```

## Main commands

Below is description of the available commands. They should be run in the Linux
terminal. The commands are located in the `bin` directory as should be run from
the main repository directory with `bin/<command> [<arguments>...]`.

### prepare\_samples

{prepare_samples}

### tf

{tf}

### plot\_idd\_stations [Figure 1a]

{plot_idd_stations}

### plot\_sample [Figure 1b, c]

{plot_sample}

### plot\_training\_history [Figure 3]

{plot_training_history}

### merge\_samples

{merge_samples}

### calc\_dtau\_pct

{calc_dtau_pct}

### plot\_dtau\_pct [Figure 6]

{plot_dtau_pct}

### calc\_geo\_cto

{calc_geo_cto}

### plot\_geo\_cto [Figure 4, 5]

{plot_geo_cto}

### plot\_geo\_cto\_rmse [Figure 11b, c, d]

{plot_geo_cto_rmse}

### calc\_cto

{calc_cto}

### plot\_cto [Figure 10]

{plot_cto}

### calc\_cto\_ecs

{calc_cto_ecs}

### plot\_cto\_ecs [Figure 11a]

{plot_cto_ecs}

### plot\_tf\_scheme [Figure 2]

{plot_tf_scheme}

## Auxiliary commands

### build\_readme

{build_readme}

### download\_cmip

{download_cmip}

### create\_by\_model

```
Create a by-model index of CMIP data. This command should be run in the
directory with CMIP data.

Usage: create_by_model

Example:

cd data/cmip5/historical/day
./create_by_model
```

### create\_by\_var

```
Create a by-var index of CMIP data. This command should be run in the
directory with CMIP data.

Usage: create_by_var

Example:

cd data/cmip5/historical/day
./create_by_var
```

### gistemp\_to\_nc

{gistemp_to_nc}

## License

MIT License

Copyright (C) 2020-2022 Peter Kuma

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
