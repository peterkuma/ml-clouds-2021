#!/usr/bin/env python3
'''Calculate geographical distribution of cloud type occurrence distribution.

Usage: calc_geo_cto INPUT [INPUT_NIGHT] TAS OUTPUT [OPTIONS]

Arguments:

  INPUT        Input file or directory (NetCDF). The output of tf.
  INPUT_NIGHT  Input directory daily files - nightime samples (NetCDF). The output of tf.
  TAS          Input file with tas. The output of gistemp_to_nc (NetCDF).
  OUTPUT       Output file (NetCDF).

Options:

  resolution: VALUE  Resolution (degrees). Default: 5. 180 must be divisible by <value>.

Examples:

bin/calc_geo_cto data/samples_pred/ceres input/tas/historical/CERES.nc data/geo_cto/historical/all/CERES.nc
bin/calc_geo_cto data/samples_pred/historical/AWI-ESM-1-1-LR input/tas/historical/AWI-ESM-1-1-LR data/geo_cto/historical/all/AWI-ESM-1-1-LR.nc
'''

import sys
import os
import ds_format as ds
import numpy as np
import aquarius_time as aq
import scipy.stats
import pst

def calc_geo_cto(stats, lat, lon, lat_bnds, lon_bnds):
	nsamples = stats.shape[0]
	nlat = len(lat_bnds) - 1
	nlon = len(lon_bnds) - 1
	out = np.zeros((nlat, nlon), np.float64)
	n = np.zeros((nlat, nlon), np.int64)
	for l in range(nsamples):
		lat1 = lat[l,:,:].flatten()
		lon1 = lon[l,:,:].flatten()
		ii = np.searchsorted(lat_bnds, lat1, side='right') - 1
		jj = np.searchsorted(lon_bnds, lon1, side='right') - 1
		out[ii,jj] += stats[l,:,:].flatten()
		n[ii,jj] += 1
	return out, n

def merge_stats_geo(a, an, b, bn):
	c = np.full(a.shape, np.nan, np.float64)
	mask = an == 0
	c[~mask] = a[~mask]
	c[mask] = b[mask]
	return c

def read_tas(filename):
	print('<- %s' % filename)
	d = ds.read(filename, jd=True)
	t1, t2 = d['time'][0], d['time'][-1]
	y1, y2 = aq.to_date(t1)[1][0], aq.to_date(t2)[1][0]
	n = y2 - y1 + 1
	time = np.full(n, np.nan, np.float64)
	tas = np.full(n, np.nan, np.float64)
	year = np.full(n, np.nan, np.float64)
	for i, y in enumerate(range(y1, y2 + 1)):
		t01 = aq.from_date([0, y, 1, 1, 0, 0, 0, 0])
		t02 = aq.from_date([0, y + 1, 1, 1, 0, 0, 0, 0])
		mask = (d['time'] >= t01) & (d['time'] < t02)
		year[i] = y
		time[i] = t01
		tas[i] = np.mean(d['tas'][mask])
	return {
		'time': time,
		'year': year,
		'tas': tas,
	}

if __name__ == '__main__':
	args, opts = pst.decode_argv(sys.argv, as_unicode=True)
	if len(args) not in (4, 5):
		sys.stderr.write(sys.modules[__name__].__doc__)
		sys.exit(1)
	input_ = args[1]
	if len(args) == 5:
		input_night = args[2]
	else:
		input_night = None
	tas = args[-2]
	output = args[-1]
	resolution = opts.get('resolution', 5)

	if 180 % resolution != 0:
		raise ValueError('180 must be divisible by resolution')

	lon_bnds = np.arange(-180., 180. + resolution, resolution)
	lat_bnds = np.arange(-90., 90. + resolution, resolution)

	d_tas = read_tas(tas) if tas is not None else None

	if os.path.isdir(input_):
		files = sorted(os.listdir(input_))
		files = [os.path.join(input_, x) for x in files if x.endswith('.nc')]
	else:
		files = [input_]

	d = ds.read(files[0])

	nclasses = d['stats'].shape[3]
	lon = 0.5*(lon_bnds[1:] + lon_bnds[:-1])
	lat = 0.5*(lat_bnds[1:] + lat_bnds[:-1])
	nlat = len(lat)
	nlon = len(lon)
	time = []
	year = []
	x = [[] for i in range(nclasses)]
	x_n = [[] for i in range(nclasses)]

	for filename in files:
		file_ = os.path.basename(filename)
		print('<- %s' % filename)
		d = ds.read(filename)
		if input_night is not None:
			d_night = ds.read(os.path.join(input_night, file_))
		days = np.array(sorted(set(d['time'])))
		for i in range(nclasses):
			for day in days:
				mask = d['time'] == day
				x_day, x_day_n = calc_geo_cto(
					d['stats'][mask,:,:,i],
					d['lat'][mask,::],
					d['lon'][mask,::],
					lat_bnds,
					lon_bnds,
				)
				x[i] += [x_day]
				x_n[i] += [x_day_n]
		time += [days]

	for i in range(nclasses):
		x[i] = np.stack(x[i])
		x_n[i] = np.stack(x_n[i])

	x = np.stack(x)
	x_n = np.stack(x_n)
	time = np.hstack(time)
	year = aq.to_date(time)[1]

	years = np.array(sorted(set(year)))
	x_yearly = []
	for y in years:
		mask = year == y
		x_yearly += [np.nanmean(x[:,mask,:,:], axis=1)]
	x_yearly = np.moveaxis(np.stack(x_yearly), 0, 1)

	x_tas = np.full((nclasses, nlat, nlon), np.nan)
	if tas is not None and len(years) > 1:
		xx = np.array([d_tas['tas'][d_tas['year'] == y][0] for y in years])
		for k in range(nclasses):
			for i in range(nlat):
				for j in range(nlon):
					yy = x_yearly[k,:,i,j]
					res = scipy.stats.linregress(xx, yy)
					x_tas[k,i,j] = res.slope

	do = {
		'cloud_occurrence': np.nansum(x, axis=1)/np.nansum(x_n, axis=1),
		'cloud_occurrence_daily': x/x_n,
		'cloud_occurrence_tas': x_tas,
		'time': time,
		'lat_bnds': lat_bnds,
		'lon_bnds': lon_bnds,
		'lat': lat,
		'lon': lon,
		'.': {
			'cloud_occurrence': {
				'.dims': ['cloud_type', 'lat', 'lon'],
				'long_name': 'cloud occurrence',
				'units': '1',
			},
			'cloud_occurrence_daily': {
				'.dims': ['cloud_type', 'time', 'lat', 'lon'],
				'long_name': 'cloud occurrence',
				'units': '1',
			},
			'cloud_occurrence_tas': {
				'.dims': ['cloud_type', 'lat', 'lon'],
				'long_name': 'cloud_occurrence',
				'units': 'K-1',
			},
			'cloud_type': {
				'.dims': ['cloud_type'],
				'long_name': 'cloud type',
			},
			'time': {
				'.dims': ['time'],
				'long_name': 'time',
				'units': 'days since -4713-11-24 12:00 UTC',
				'calendar': 'proleptic_gregorian',
			},
			'lat': {
				'.dims': ['lat'],
				'long_name': 'latitude',
				'units': 'degrees_north',
			},
			'lon': {
				'.dims': ['lon'],
				'long_name': 'longitude',
				'units': 'degrees_east',
			},
			'lat_bnds': {
				'.dims': ['lat_bnds'],
				'long_name': 'latitude bounds',
				'units': 'degrees_north',
			},
			'lon_bnds': {
				'.dims': ['lon_bnds'],
				'long_name': 'longitude bounds',
				'units': 'degrees_east',
			},
		}
	}
	print('-> %s' % output)
	ds.write(output, do)
