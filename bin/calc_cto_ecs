#!/usr/bin/env python3
'''Calculate cloud type occurrence vs. ECS regression.

Usage: calc_cto_ecs <input> <ecs> <output>

Depends on: calc_cto

Arguments:

- input: Input directory - the output of calc_geo_cto (NetCDF).
- ecs: ECS, TCR and CLD input (CSV).
- output: Output file (NetCDF).

Examples:

bin/calc_cto_ecs data/geo_cto/abrupt-4xCO2/ input/ecs/ecs.csv data/cto_ecs/cto_ecs.nc
'''

import sys
import os
import ds_format as ds
import numpy as np
import aquarius_time as aq
import pandas as pd
import pymc3 as pm

CLOUD_TYPES = ['High', 'Middle', 'Cumuliform', 'Stratiform']
VARS = ['ecs']
NBURN = 1000
NSAMPLES = 100000
NCHAINS = 24
NCORES = 24

def bayes(x, y, nsamples=NSAMPLES, nburn=NBURN, nchains=NCHAINS, ncores=NCORES):
	x_m = np.mean(x)
	x_sd = np.std(x)
	y_m = np.mean(y)
	y_sd = np.std(y)
	xn = (x - x_m)/x_sd
	yn = (y - y_m)/y_sd

	with pm.Model() as model:
		model_sel = pm.DiscreteUniform('model_sel', lower=0, upper=1)
		c0 = pm.Uniform('c0', lower=-100, upper=100)
		c1ang = pm.Uniform('c1ang', lower=-np.pi/2, upper=np.pi/2)
		mu = c0 + model_sel*np.tan(c1ang)*xn
		sd = pm.Uniform('sd', lower=0, upper=100)
		obs = pm.Cauchy('obs', mu, sd, observed=yn)

	with model:
		step = pm.Metropolis()
		trace = pm.sample(nsamples + nburn, step, chains=nchains, cores=ncores, progressbar=True)
		c0 = trace['c0'][(nburn*nchains):]
		c1ang = trace['c1ang'][(nburn*nchains):]
		c1 = np.tan(c1ang)
		sd = trace['sd'][(nburn*nchains):]
		model_sel = trace['model_sel'][(nburn*nchains):]
		mask = model_sel == 1
		c0 = c0[mask]
		c1 = c1[mask]
		sd = sd[mask]
		return \
			c0*y_sd + y_m - c1*y_sd/x_sd*x_m, \
			c1*y_sd/x_sd, \
			sd*y_sd, \
			(np.mean(model_sel)/(1-np.mean(model_sel)))

def read_ecs(filename):
	d = pd.read_csv(filename)
	return {
		'model': np.array(d['Model']),
		'ecs': np.array(d['ECS']),
		'tcr': np.array(d['TCR']),
		'cld': np.array(d['CLD']),
	}

def geomean(x, lat, lon):
	w = np.cos(lat/180*np.pi)
	w /= np.sum(w)
	return np.mean(np.average(x[:,:], weights=w, axis=0), axis=0)

if __name__ == '__main__':
	if len(sys.argv) != 4:
		sys.stderr.write(sys.modules[__name__].__doc__)
		sys.exit(1)
	input_ = sys.argv[1]
	ecs = sys.argv[2]
	output = sys.argv[3]

	print('<- %s' % input_)
	dd = ds.readdir(input_, ['cloud_occurrence_tas', 'lat', 'lon'])
	d = ds.merge(dd, 'model')
	d_ecs = read_ecs(ecs)

	d['models'] = [os.path.basename(fname)[:-3] for fname in d['filename']]

	n, m = d['cloud_occurrence_tas'].shape[0:2]
	x = np.full((n, m), np.nan, np.float64)
	for i, model in enumerate(d['models']):
		for j in range(m):
			x[i,j] = geomean(d['cloud_occurrence_tas'][i,j],
				d['lat'][i], d['lon'][i])
	d['cloud_occurrence_tas'] = x

	vars_ = {}
	for k in VARS:
		vars_[k] = [d_ecs[k][d_ecs['model'] == model] for model in d['models']]
		vars_[k] = np.array([x[0] if len(x) == 1 else np.nan for x in vars_[k]])

	c0 = {}
	c1 = {}
	p = {}
	c0_sample = {}
	c1_sample = {}
	err_sample = {}
	sd_sample = {}
	bf = {}
	for k in VARS:
		c0[k] = np.full(m, np.nan)
		c1[k] = np.full(m, np.nan)
		bf[k] = np.full(m, np.nan)
		p[k] = np.full(m, np.nan)
		c0_sample[k] = np.full((m, NSAMPLES*NCHAINS), np.nan)
		c1_sample[k] = np.full((m, NSAMPLES*NCHAINS), np.nan)
		err_sample[k] = np.full((m, NSAMPLES*NCHAINS), np.nan)
		sd_sample[k] = np.full((m, NSAMPLES*NCHAINS), np.nan)
		var = vars_[k]
		for i, cloud_type in enumerate(CLOUD_TYPES):
			mask = np.isfinite(var) & np.isfinite(d['cloud_occurrence_tas'][:,i])
			c0_samples, c1_samples, sd_samples, bf1 = \
				bayes(d['cloud_occurrence_tas'][mask,i]*100, var[mask])
			c0_sample[k][i,:len(c0_samples)] = c0_samples
			c1_sample[k][i,:len(c1_samples)] = c1_samples
			sd_sample[k][i,:len(sd_samples)] = sd_samples
			c0[k][i] = np.nanmean(c0_sample[k][i,:])
			c1[k][i] = np.nanmean(c1_sample[k][i,:])
			bf[k][i] = bf1

	do = {'.': {}}
	do['cloud_occurrence_tas'] = d['cloud_occurrence_tas']
	do['.']['cloud_occurrence_tas'] = {'.dims': ['model', 'cloud_type']}
	for k in VARS:
		do.update({
			k: vars_[k],
			('bf_'+k): bf[k],
			('c0_'+k): c0[k],
			('c1_'+k): c1[k],
			('sd_'+k+'_samples'): sd_sample[k],
			('c1_'+k+'_samples'): c1_sample[k],
		})
		do['.'].update({
			k: {'.dims': ['model']},
			('bf_'+k): {'.dims': ['cloud_type']},
			('c0_'+k): {'.dims': ['cloud_type']},
			('c1_'+k): {'.dims': ['cloud_type']},
			('sd_'+k+'_samples'): {'.dims': ['cloud_type', 'sample']},
			('c1_'+k+'_samples'): {'.dims': ['cloud_type', 'sample']},
		})
	print('-> %s' % output)
	ds.write(output, do)
